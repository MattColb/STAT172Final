summary(cps_data)
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_on_assistance)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Iowa Residents on Food Stamps or SNAP",
fill = "Proportion of\nResidents")
map_data <- sf_data %>%
left_join(summary_by_PUMA, by = "PUMA")
#https://www.geoplatform.gov/metadata/258db7ce-2581-4488-bb5e-e387b6119c7a
sf_data <- st_read("./data/tl_2023_19_puma20/tl_2023_19_puma20.shp")
colnames(sf_data)[colnames(sf_data) == "GEOID20"] = "PUMA"
map_data <- sf_data %>%
left_join(summary_by_PUMA, by = "PUMA")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_on_assistance)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Iowa Residents on Food Stamps or SNAP",
fill = "Proportion of\nResidents")
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
acs_test_data <- model.matrix(~hhsize + married + education + elderly +
kids + black + hispanic + female, data=acs_data)[,-1]
fsstmp_predictions <- predict(lr_lasso_fsstmp, acs_test_data, type="response")[,1]
acs_predicted <- acs_data %>% mutate(
fsstmp_prediction = ifelse(fsstmp_predictions > lasso_fsstmp_pi_star, "On Assistance", "Not On Assistance")
)
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
#https://www.geoplatform.gov/metadata/258db7ce-2581-4488-bb5e-e387b6119c7a
sf_data <- st_read("./data/tl_2023_19_puma20/tl_2023_19_puma20.shp")
colnames(sf_data)[colnames(sf_data) == "GEOID20"] = "PUMA"
map_data <- sf_data %>%
left_join(summary_by_PUMA, by = "PUMA")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_on_assistance)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Iowa Residents on Food Stamps or SNAP",
fill = "Proportion of\nResidents")
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size,
has_senior = ifelse(elderly > 0, "Has Senior", "No Senior")
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
#https://www.geoplatform.gov/metadata/258db7ce-2581-4488-bb5e-e387b6119c7a
sf_data <- st_read("./data/tl_2023_19_puma20/tl_2023_19_puma20.shp")
colnames(sf_data)[colnames(sf_data) == "GEOID20"] = "PUMA"
map_data <- sf_data %>%
left_join(summary_by_PUMA, by = "PUMA")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_on_assistance)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Iowa Residents on Food Stamps or SNAP",
fill = "Proportion of\nResidents")
summary_by_PUMA
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size,
has_senior = sum(ifelse(elderly > 0, "Has Senior", "No Senior"))
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size,
has_senior = sum(ifelse(elderly > 0, 1, 0))
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
summary_by_PUMA
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size,
has_senior = sum(ifelse(elderly > 0, 1, 0)),
proportion_has_senior = has_senior/sample_size
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
#https://www.geoplatform.gov/metadata/258db7ce-2581-4488-bb5e-e387b6119c7a
sf_data <- st_read("./data/tl_2023_19_puma20/tl_2023_19_puma20.shp")
colnames(sf_data)[colnames(sf_data) == "GEOID20"] = "PUMA"
map_data <- sf_data %>%
left_join(summary_by_PUMA, by = "PUMA")
ggplot(data = map_data) +
geom_sf(aes(fill = has_senior)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Iowa Residents on Food Stamps or SNAP",
fill = "Proportion of\nResidents")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_has_senior)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Iowa Residents on Food Stamps or SNAP",
fill = "Proportion of\nResidents")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_has_senior)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Proportion of Households with Senior",
fill = "Proportion of\Households with\nSeniors")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_has_senior)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Proportion of Households with Senior",
fill = "Proportion of\nHouseholds with\nSeniors")
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size,
only_seniors = sum(ifelse(elderly == hhsize, 1, 0)),
proportion_only_senior = only_senior/sample_size,
has_senior = sum(ifelse(elderly > 0, 1, 0)),
proportion_has_senior = has_senior/sample_size
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
#How does this adjust with the weights
summary_by_PUMA <- acs_predicted %>% group_by(PUMA = as.factor(PUMA)) %>%
summarise(
sample_size = sum(hhsize),
total_weights = sum(weight),
total_weights_by_sample = sum(weight *hhsize),
people_on_assistance = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)),
people_on_assistance_weighted = sum(ifelse(fsstmp_prediction == "On Assistance", 1, 0)*weight),
proportion_on_assistance = people_on_assistance/sample_size,
only_senior = sum(ifelse(elderly == hhsize, 1, 0)),
proportion_only_senior = only_senior/sample_size,
has_senior = sum(ifelse(elderly > 0, 1, 0)),
proportion_has_senior = has_senior/sample_size
) %>% as.data.frame() %>% arrange(desc(proportion_on_assistance))
#https://www.geoplatform.gov/metadata/258db7ce-2581-4488-bb5e-e387b6119c7a
sf_data <- st_read("./data/tl_2023_19_puma20/tl_2023_19_puma20.shp")
colnames(sf_data)[colnames(sf_data) == "GEOID20"] = "PUMA"
map_data <- sf_data %>%
left_join(summary_by_PUMA, by = "PUMA")
ggplot(data = map_data) +
geom_sf(aes(fill = proportion_only_senior)) +
scale_fill_viridis_c(option = "plasma") +  # Adjust color palette as needed
theme_minimal() +
labs(title = "Proportion of Households with Senior",
fill = "Proportion of\nHouseholds with\nSeniors")
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = reduced_train[col1] * reduced_train[col2])
interaction_test = reduced_test %>%
mutate(interaction_term = reduced_test[col1] * reduced_test[col2])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
lr_lasso_fsstmp_cv <- cv.glmnet(proper_train_x, FSSTMP.y.train,
family=binomial(link="logit"), alpha=1, weights=train.weights)
best_lasso_lambda_fsstmp <- lr_lasso_fsstmp_cv$lambda.min #GOOD
lr_lasso_fsstmp <- glmnet(proper_train_x, FSSTMP.y.train, family=binomial(link="logit"),
alpha=1, lambda = best_lasso_lambda_fsstmp, weights=train.weights)
lasso_fsstmp_rocCurve <- roc(response = as.factor(FSSTMP.y.test),
predictor = predict(lr_lasso_fsstmp, proper_test_x, type="response")[,1],
levels=c("0", "1"))
interaction_df[inc, "added_interaction"] = str
interaction_df[inc, "AUC"] = lasso_fsstmp_rocCurve$auc
inc = inc + 1
}
}
interaction_train
reduced_train[col1]
cps_data <- as.data.frame(cps_data)
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
reduced_train[col1]
reduced_train
###############################
#       Train Test Split      #
###############################
RNGkind(sample.kind = "default")
set.seed(159159)
train.idx <- sample(x=1:nrow(cps_data), size=.7*nrow(cps_data))
train.df <- cps_data[train.idx,]
test.df <- cps_data[-train.idx,]
test.df.preds <- test.df
###########################
#   Food Stamp Analysis   #
###########################
#Things to think about/do
#Fit a random forest
#Fit a cluster?
#What are the weights doing?
#Think about what I could do with NA values
#Make plots/clean up ROC plots
###########################
#   Train Test Split      #
###########################
FSSTMP.x.train <- model.matrix(FSSTMPVALC_bin ~ hhsize + married +
education + elderly +
kids + black + hispanic + female
, data=train.df)[,-1]
FSSTMP.x.test <- model.matrix(FSSTMPVALC_bin ~ hhsize + married +
education + elderly +
kids + black + hispanic + female
, data=test.df)[,-1]
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
train.weights <- as.vector(train.df$weight)
test.weights <- as.vector(test.df$weight)
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = reduced_train[col1] * reduced_train[col2])
interaction_test = reduced_test %>%
mutate(interaction_term = reduced_test[col1] * reduced_test[col2])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
lr_lasso_fsstmp_cv <- cv.glmnet(proper_train_x, FSSTMP.y.train,
family=binomial(link="logit"), alpha=1, weights=train.weights)
best_lasso_lambda_fsstmp <- lr_lasso_fsstmp_cv$lambda.min #GOOD
lr_lasso_fsstmp <- glmnet(proper_train_x, FSSTMP.y.train, family=binomial(link="logit"),
alpha=1, lambda = best_lasso_lambda_fsstmp, weights=train.weights)
lasso_fsstmp_rocCurve <- roc(response = as.factor(FSSTMP.y.test),
predictor = predict(lr_lasso_fsstmp, proper_test_x, type="response")[,1],
levels=c("0", "1"))
interaction_df[inc, "added_interaction"] = str
interaction_df[inc, "AUC"] = lasso_fsstmp_rocCurve$auc
inc = inc + 1
}
}
reduced_train
reduced_train[col1]
reduced_train[col1]*reduced_train[col2]
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = reduced_train[col1] * reduced_train[col2])
interaction_test = reduced_test %>%
mutate(interaction_term = reduced_test[col1] * reduced_test[col2])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
lr_lasso_fsstmp_cv <- cv.glmnet(proper_train_x, FSSTMP.y.train,
family=binomial(link="logit"), alpha=1, weights=train.weights)
best_lasso_lambda_fsstmp <- lr_lasso_fsstmp_cv$lambda.min #GOOD
lr_lasso_fsstmp <- glmnet(proper_train_x, FSSTMP.y.train, family=binomial(link="logit"),
alpha=1, lambda = best_lasso_lambda_fsstmp, weights=train.weights)
lasso_fsstmp_rocCurve <- roc(response = as.factor(FSSTMP.y.test),
predictor = predict(lr_lasso_fsstmp, proper_test_x, type="response")[,1],
levels=c("0", "1"))
interaction_df[inc, "added_interaction"] = str
interaction_df[inc, "AUC"] = lasso_fsstmp_rocCurve$auc
inc = inc + 1
}
}
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = reduced_train[col1] * reduced_train[col2])
interaction_test = reduced_test %>%
mutate(interaction_term = reduced_test[col1] * reduced_test[col2])
inc = inc + 1
}
}
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = reduced_train[col1] * reduced_train[col2])
interaction_test = reduced_test %>%
mutate(interaction_term = reduced_test[col1] * reduced_test[col2])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
inc = inc + 1
}
}
interaction_train
str(interaction_train)
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = as.vector(reduced_train[col1]) * as.vector(reduced_train[col2]))
interaction_test = reduced_test %>%
mutate(interaction_term = reduced_test[col1] * reduced_test[col2])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
inc = inc + 1
}
}
interaction_train = reduced_train %>%
mutate(interaction_term = as.numeric(reduced_train[col1]) * as.numeric(reduced_train[col2]))
interaction_train
str(interaction_train)
reduced_train[col1] * reduced_train[col2]
(reduced_train[col1] * reduced_train[col2])[,1]
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:9){
for (j in 1:9){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = (reduced_train[col1] * reduced_train[col2])[,1])
interaction_test = reduced_test %>%
mutate(interaction_term = (reduced_test[col1] * reduced_test[col2])[,1])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
inc = inc + 1
}
}
str(interaction_train)
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:2){
for (j in 1:2){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = (reduced_train[col1] * reduced_train[col2])[,1])
interaction_test = reduced_test %>%
mutate(interaction_term = (reduced_test[col1] * reduced_test[col2])[,1])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
inc = inc + 1
}
}
reduced_train = train.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
reduced_test = test.df %>%
select(c("weight", "hhsize", "female", "hispanic", "black",
"kids", "elderly", "education", "married", "FSSTMPVALC_bin"))
FSSTMP.y.train <- as.vector(train.df$FSSTMPVALC_bin)
FSSTMP.y.test <- as.vector(test.df$FSSTMPVALC_bin)
interaction_df = data.frame(added_interaction=rep(NA, 81), AUC=rep(NA, 81))
inc = 1
for(i in 1:2){
for (j in 1:2){
col1 = colnames(reduced_train)[i][1]
col2 = colnames(reduced_train)[j][1]
str = paste(col1, col2, sep="_")
interaction_train = reduced_train %>%
mutate(interaction_term = (reduced_train[col1] * reduced_train[col2])[,1])
interaction_test = reduced_test %>%
mutate(interaction_term = (reduced_test[col1] * reduced_test[col2])[,1])
proper_train_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_train)[,-1]
proper_test_x = model.matrix(FSSTMPVALC_bin ~ .
, data=interaction_test)[,-1]
lr_lasso_fsstmp_cv <- cv.glmnet(proper_train_x, FSSTMP.y.train,
family=binomial(link="logit"), alpha=1, weights=train.weights)
best_lasso_lambda_fsstmp <- lr_lasso_fsstmp_cv$lambda.min #GOOD
lr_lasso_fsstmp <- glmnet(proper_train_x, FSSTMP.y.train, family=binomial(link="logit"),
alpha=1, lambda = best_lasso_lambda_fsstmp, weights=train.weights)
lasso_fsstmp_rocCurve <- roc(response = as.factor(FSSTMP.y.test),
predictor = predict(lr_lasso_fsstmp, proper_test_x, type="response")[,1],
levels=c("0", "1"))
interaction_df[inc, "added_interaction"] = str
interaction_df[inc, "AUC"] = lasso_fsstmp_rocCurve$auc
inc = inc + 1
}
}
warnings()
